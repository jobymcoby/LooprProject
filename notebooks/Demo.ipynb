{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import scipy\n",
    "import pathlib\n",
    "import winsound\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tqdm as notebook_tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The textile fabric database consists of 245 images of 7 different fabrics. There are 140 defect-free images, 20 for each type of fabric. With different types of defects, there are 105 images.\n",
    "\n",
    "Images have a size of 4096Ã—256 pixels. Defective images have been denominated as follows: nnnn_ddd_ff.png, where nnnn is the image number, ddd is the defect code, and ff is the fabric code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defects found: 106\n",
      "No Defects found: 141\n"
     ]
    }
   ],
   "source": [
    "dataset_folder = \"..\\\\archive\"  \n",
    "no_defect_images_folder = os.path.join(dataset_folder, \"NODefect_images\")\n",
    "defect_images_folder = os.path.join(dataset_folder, \"Defect_images\")\n",
    "mask_images_folder = os.path.join(dataset_folder, \"Mask_images\")\n",
    "\n",
    "def gather_filenames(mypath: os.path) -> list[str]:\n",
    "    filepaths = []\n",
    "    for path, _, files in os.walk(mypath):\n",
    "        for name in files:\n",
    "            filepaths.append(os.path.join(path, name))\n",
    "    return filepaths\n",
    "\n",
    "defect_file_paths = gather_filenames(defect_images_folder)\n",
    "no_defect_file_paths = gather_filenames(no_defect_images_folder)\n",
    "\n",
    "print(f'Defects found: {len(defect_file_paths)}\\nNo Defects found: {len(no_defect_file_paths)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected defects\n",
    "DEFECT_CODES = {\n",
    "    0:  'No defect',\n",
    "    2:\t'Broken end',\n",
    "    6:\t'Broken yarn',\n",
    "    # 10:\t'Broken pick',\n",
    "    # 16:\t'Weft curling',\n",
    "    # 19:\t'Fuzzyball',\n",
    "    # 22: 'Cut selvage',\n",
    "    23: 'Crease',  \n",
    "    # 25:\t'Warp ball',\n",
    "    # 27: 'Knots',\n",
    "    # 29: 'Contamination',\n",
    "    30:  'Nep',\n",
    "    # 36: 'Weft crack'\n",
    "}\n",
    "output_len = len(DEFECT_CODES)\n",
    "\n",
    "#encode defects to 0-12\n",
    "DEFECT_ENCODINGS = {}\n",
    "for i, key in zip(range(len(DEFECT_CODES)) , DEFECT_CODES.keys()):\n",
    "    DEFECT_ENCODINGS[key] = i\n",
    "\n",
    "def extract_labels(filepaths: list[str]) -> pd.DataFrame:\n",
    "    file_df = pd.DataFrame(filepaths, columns=['filepath'])\n",
    "\n",
    "    # x.split('\\\\') willl give the filename, then x.split('_') will give the labels\n",
    "    file_df['id'] = file_df['filepath'].map(lambda x: int(x.split('\\\\')[-1].split('_')[0]))\n",
    "    file_df['defect'] = file_df['filepath'].map(lambda x: int(x.split('\\\\')[-1].split('_')[1]))\n",
    "    file_df['fabric'] = file_df['filepath'].map(lambda x: int(x.split('\\\\')[-1].split('_')[2].split('.')[0]))\n",
    "    return file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files names to image dataset\n",
    "defect_file_df = extract_labels(defect_file_paths)\n",
    "no_defect_file_df = extract_labels(no_defect_file_paths)\n",
    "\n",
    "# # drop unwanted labels\n",
    "defect_file_df = defect_file_df.drop(defect_file_df[defect_file_df['defect'] == 10].index)\n",
    "defect_file_df = defect_file_df.drop(defect_file_df[defect_file_df['defect'] == 16].index)\n",
    "defect_file_df = defect_file_df.drop(defect_file_df[defect_file_df['defect'] == 19].index)\n",
    "defect_file_df = defect_file_df.drop(defect_file_df[defect_file_df['defect'] == 22].index)\n",
    "# defect_file_df = defect_file_df.drop(defect_file_df[defect_file_df['defect'] == 23].index)\n",
    "defect_file_df = defect_file_df.drop(defect_file_df[defect_file_df['defect'] == 25].index)\n",
    "defect_file_df = defect_file_df.drop(defect_file_df[defect_file_df['defect'] == 27].index)\n",
    "defect_file_df = defect_file_df.drop(defect_file_df[defect_file_df['defect'] == 29].index)\n",
    "# defect_file_df = defect_file_df.drop(defect_file_df[defect_file_df['defect'] == 30].index)\n",
    "defect_file_df = defect_file_df.drop(defect_file_df[defect_file_df['defect'] == 36].index)\n",
    "\n",
    "# Select Defects to encode\n",
    "defect_file_df['defect'] = defect_file_df['defect'].map(lambda x: DEFECT_ENCODINGS[x])\n",
    "no_defect_file_df['defect'] = no_defect_file_df['defect'].map(lambda x: DEFECT_ENCODINGS[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = defect_file_df['defect'].value_counts().sort_index().plot(kind = 'bar', title='Defect Frequency')\n",
    "plt.xticks(range(0,len(DEFECT_CODES) - 1), list(DEFECT_CODES.values())[1:])\n",
    "ax.xaxis.set_tick_params(rotation=30, labelsize=8)\n",
    "plt.gca().spines[['top', 'right',]].set_visible(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file_path: tf.Tensor, label: tf.Tensor) -> tuple[tf.Tensor, tf.Tensor, tf.Tensor]:\n",
    "    image = tf.io.read_file(file_path)\n",
    "    image = tf.io.decode_png(image, channels=1)\n",
    "    return image, label, file_path\n",
    "\n",
    "def augment(image, label, path, seed):\n",
    "    # Make new seed\n",
    "    new_seed = tf.random.split(seed, num=1)[0, :]\n",
    "    # Random brightness.\n",
    "    image = tf.image.stateless_random_brightness(\n",
    "        image, max_delta=0.5, seed=new_seed\n",
    "    )\n",
    "    # random vertical flip\n",
    "    image = tf.image.stateless_random_flip_up_down(\n",
    "        image, seed=new_seed\n",
    "    )\n",
    "\n",
    "    image = tf.image.stateless_random_contrast(\n",
    "        image, 0.2, 0.5, seed\n",
    "    )\n",
    "\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    \n",
    "    return image, label, path\n",
    "\n",
    "rng = tf.random.Generator.from_seed(123, alg='philox')\n",
    "\n",
    "def augment_update(x,y,z):\n",
    "    seed = rng.make_seeds(1)[:, 0]\n",
    "    x,y,z = augment(x, y, z, seed)\n",
    "    return x,y,z\n",
    "\n",
    "def augment_defect_images(train_ds):\n",
    "    # used to create more defect images,\n",
    "    # just a flip and brightness change \n",
    "    no_defect_train_image_ds = train_ds.filter(lambda _, label, path: label == 0)\n",
    "    defect_train_image_ds = train_ds.filter(lambda _, label, path: label > 0)\n",
    "\n",
    "    augments_per_image = 6\n",
    "    augmented_defects_ds = (\n",
    "        defect_train_image_ds\n",
    "        .repeat(augments_per_image)\n",
    "        .map(lambda x, y, z: augment_update(x, y, z))\n",
    "    )\n",
    "    # print(f\"Number of defects before augmentation: {len(list(defect_train_image_ds.as_numpy_iterator()))}\\n\")\n",
    "    # print(f\"Number of defects after augmentation: {len(list(augmented_defects_ds.as_numpy_iterator()))}\\n\")\n",
    "    # print(f\"Number of no-defects: {len(list(no_defect_train_image_ds.as_numpy_iterator()))}\\n\")\n",
    "    \n",
    "    defect_train_image_ds = defect_train_image_ds.concatenate(augmented_defects_ds)\n",
    "    return augmented_defects_ds.concatenate(no_defect_train_image_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(image, label, file_path):\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    image -= tf.reduce_mean(image, axis=0)\n",
    "    return image, label\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit([[i] for i in list(range(len(DEFECT_CODES)))])\n",
    "\n",
    "spec = tf.TensorSpec(shape=[len(DEFECT_CODES),], dtype=tf.int64)\n",
    "@tf.py_function(Tout=spec)\n",
    "def map_defect_to_one_hot(tensor):\n",
    "    tensor = enc.transform(\n",
    "        tensor.numpy().reshape(1, 1)\n",
    "        ).toarray()[0]\n",
    "    return tensor\n",
    "\n",
    "#preprocess images\n",
    "def preprocess_img(image: tf.Tensor, label: tf.Tensor) -> tuple[tf.Tensor, tf.Tensor]:\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    image = tf.image.grayscale_to_rgb(image)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "\n",
    "    # one hot encode the defects\n",
    "    label = map_defect_to_one_hot(label)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_split(file_ds, seed):\n",
    "    # shuffle\n",
    "    ds_size = len(file_ds)\n",
    "    file_ds = file_ds.shuffle(ds_size, seed=seed, reshuffle_each_iteration=False)\n",
    "\n",
    "    no_defect_ds = file_ds.filter(lambda _, label: label == 0)\n",
    "    no_defect_ds_size = len(list(no_defect_ds.as_numpy_iterator()))\n",
    "\n",
    "    # split\n",
    "    train_split = 0.70\n",
    "    no_defect_train_size = int(train_split * no_defect_ds_size)\n",
    "\n",
    "    val_split = 0.15\n",
    "    no_defect_val_size = int(val_split * no_defect_ds_size)\n",
    "\n",
    "    test_split = 0.15\n",
    "\n",
    "    nodefect_train_ds = no_defect_ds.take(no_defect_train_size)\n",
    "    nodefect_val_ds = no_defect_ds.skip(no_defect_train_size).take(no_defect_val_size)\n",
    "    nodefect_test_ds = no_defect_ds.skip(no_defect_train_size).skip(no_defect_val_size)\n",
    "\n",
    "    defect_ds = file_ds.filter(lambda _, label: label > 0)\n",
    "\n",
    "    # random over sample the defect files\n",
    "\n",
    "    defect_ds_size = len(list(defect_ds.as_numpy_iterator()))\n",
    "\n",
    "    defect_train_size = int(train_split * defect_ds_size)\n",
    "\n",
    "    defect_val_size = int(val_split * defect_ds_size)\n",
    "\n",
    "    test_split = 0.15\n",
    "\n",
    "    defect_train_ds = defect_ds.take(defect_train_size)\n",
    "    defect_val_ds = defect_ds.skip(defect_train_size).take(defect_val_size)\n",
    "    defect_test_ds = defect_ds.skip(defect_train_size).skip(defect_val_size)\n",
    "\n",
    "    train_ds = nodefect_train_ds.concatenate(defect_train_ds)\n",
    "    val_ds = nodefect_val_ds.concatenate(defect_val_ds)\n",
    "    test_ds = nodefect_test_ds.concatenate(defect_test_ds)\n",
    "\n",
    "    train_ds = train_ds.shuffle(defect_train_size + no_defect_train_size, seed=seed, reshuffle_each_iteration=False)\n",
    "    val_ds = val_ds.shuffle(defect_val_size + defect_val_size, seed=seed, reshuffle_each_iteration=False)\n",
    "    test_ds = test_ds.shuffle(defect_val_size + defect_val_size, seed=seed, reshuffle_each_iteration=False)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "def k_fold(file_ds):\n",
    "    #5 folds\n",
    "    rng = tf.random.Generator.from_seed(123, alg='philox')\n",
    "    seeds = rng.make_seeds(5)[:].numpy()[0]\n",
    "\n",
    "    folds = [shuffle_split(file_ds, seed) for seed in seeds]\n",
    "    return folds\n",
    "\n",
    "\n",
    "# Files names to image dataset\n",
    "full_file_df = pd.concat([defect_file_df, no_defect_file_df])\n",
    "\n",
    "files_arr = full_file_df['filepath'].to_numpy()\n",
    "labels_arr = full_file_df['defect'].to_numpy()\n",
    "\n",
    "# Tf dataset\n",
    "file_ds = tf.data.Dataset.from_tensor_slices((files_arr, labels_arr))\n",
    "\n",
    "# get 5 random splits for  cross validation\n",
    "data_splits = k_fold(file_ds)\n",
    "\n",
    "def prepare_data(kfold):\n",
    "    train_ds, val_ds, test_ds = kfold[0], kfold[1], kfold[2],\n",
    "    val_ds = val_ds.map(load_image)\n",
    "    test_ds = test_ds.map(load_image)\n",
    "    train_ds = train_ds.map(load_image)\n",
    "\n",
    "    rng = tf.random.Generator.from_seed(123, alg='philox')\n",
    "    aug_train_ds = augment_defect_images(train_ds)\n",
    "\n",
    "    val_ds = val_ds.map(lambda x,y,z: normalize(x,y,z))\n",
    "    test_ds = test_ds.map(lambda x,y,z: normalize(x,y,z))\n",
    "    train_ds = train_ds.map(lambda x,y,z: normalize(x,y,z))\n",
    "    aug_train_ds = aug_train_ds.map(lambda x,y,z: normalize(x,y,z))\n",
    "\n",
    "    val_ds = val_ds.map(lambda x,y: preprocess_img(x,y))\n",
    "    test_ds = test_ds.map(lambda x,y: preprocess_img(x,y))\n",
    "    train_ds = train_ds.map(lambda x,y: preprocess_img(x,y))\n",
    "    aug_train_ds = aug_train_ds.map(lambda x,y: preprocess_img(x,y))\n",
    "\n",
    "    val_ds = val_ds.batch(4, drop_remainder=True)\n",
    "    test_ds = test_ds.batch(4, drop_remainder=True)\n",
    "    train_ds = train_ds.batch(4, drop_remainder=True)\n",
    "    aug_train_ds = aug_train_ds.batch(4, drop_remainder=True)\n",
    "\n",
    "\n",
    "    for i in aug_train_ds:\n",
    "        train_shape = (i[0].shape, i[1].shape)\n",
    "        break\n",
    "\n",
    "    def set_shapes(image, label):\n",
    "        image.set_shape(train_shape[0])\n",
    "        label.set_shape(train_shape[1])\n",
    "        return image, label\n",
    "\n",
    "    aug_train_ds = aug_train_ds.map(set_shapes)\n",
    "\n",
    "    num_batches = len(list(aug_train_ds.as_numpy_iterator()))\n",
    "    aug_train_ds = aug_train_ds.apply(tf.data.experimental.assert_cardinality(num_batches))\n",
    "    return aug_train_ds, train_ds, val_ds, test_ds\n",
    "\n",
    "# prep k fold for training and eval\n",
    "data_splits = [prepare_data(kfold) for kfold in data_splits]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_tensor_as_image(tensor: tf.Tensor):\n",
    "    print(tensor.shape)\n",
    "    plt.gray()\n",
    "    plt.imshow(tensor.numpy())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(15,15))\n",
    "    axs[0].plot(history.history['loss'])\n",
    "    axs[0].plot(history.history['val_loss'])\n",
    "    axs[0].title.set_text('Training Loss vs Validation Loss')\n",
    "    axs[0].set_xlabel('Epochs')\n",
    "    axs[0].set_ylabel('Loss')\n",
    "    axs[0].legend(['Train','Val'])\n",
    "    axs[1].plot(history.history['accuracy'])\n",
    "    axs[1].plot(history.history['val_accuracy'])\n",
    "    axs[1].title.set_text('Training Accuracy vs Validation Accuracy')\n",
    "    axs[1].set_xlabel('Epochs')\n",
    "    axs[1].set_ylabel('Accuracy')\n",
    "    axs[1].legend(['Train', 'Val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_matrix(val_ds, head_model):    \n",
    "    metric = tf.keras.metrics.F1Score()\n",
    "\n",
    "    test_y_true_ds = [label.numpy() for _, label in val_ds.unbatch()]\n",
    "    test_y_true_ds = np.array(test_y_true_ds)\n",
    "    test_y_pred_ds = head_model.predict(val_ds, verbose=2)\n",
    "\n",
    "    metric.update_state(test_y_true_ds, test_y_pred_ds)\n",
    "    result = metric.result()\n",
    "\n",
    "    true_labels = np.array([np.argmax(label) for label in test_y_true_ds])\n",
    "    pred_labels = np.array([np.argmax(label) for label in test_y_pred_ds])\n",
    "    tf.math.confusion_matrix(true_labels, pred_labels)\n",
    "    return result.numpy(), tf.math.confusion_matrix(true_labels, pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning on the top layers\n",
    "# Load convolutional weights that are trained on ImageNet data\n",
    "def build_model(output_len):\n",
    "    base_model = tf.keras.applications.resnet.ResNet152(\n",
    "        weights = 'imagenet',\n",
    "        include_top = False,\n",
    "        input_shape = (224, 224, 3)\n",
    "    )\n",
    "\n",
    "    # Freeze pretrained layers\n",
    "    for layer in base_model.layers:\n",
    "      layer.trainable = False\n",
    "\n",
    "    x = tf.keras.layers.Flatten()(base_model.output)\n",
    "    x = tf.keras.layers.Dense(1000, activation='relu')(x)\n",
    "    predictions = tf.keras.layers.Dense(output_len, activation = 'softmax')(x)\n",
    "\n",
    "    head_model = tf.keras.Model(inputs = base_model.input, outputs = predictions)\n",
    "    head_model.compile(optimizer='adam', loss= tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "    return head_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\chris\\LooprProject\\Looprvenv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\chris\\LooprProject\\Looprvenv\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\chris\\LooprProject\\Looprvenv\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From d:\\chris\\LooprProject\\Looprvenv\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From d:\\chris\\LooprProject\\Looprvenv\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "62/62 [==============================] - 94s 1s/step - loss: 24.4636 - accuracy: 0.7702 - val_loss: 3.0996 - val_accuracy: 0.8077\n"
     ]
    }
   ],
   "source": [
    "def eval_kfolds(data_splits):\n",
    "    con_matrix = None\n",
    "    acc = 0\n",
    "    f_1 = 0 \n",
    "    for i, fold in enumerate(data_splits):\n",
    "        head_model = build_model(output_len)\n",
    "        aug_train_ds, train_ds, val_ds, test_ds = fold\n",
    "        val_ds = val_ds.concatenate(test_ds)\n",
    "        history = head_model.fit(aug_train_ds, epochs= 5, validation_data= val_ds)\n",
    "        plot_history(history)\n",
    "        print(f'k fold {i} acc {head_model.evaluate(val_ds)[1]}')\n",
    "        acc += head_model.evaluate(val_ds)[1]\n",
    "        print(f'k fold {i} f score and confusion matrix {f1_score_matrix(val_ds, head_model)}')\n",
    "        if con_matrix is None:\n",
    "            f_1 = f1_score_matrix(val_ds, head_model)[0]\n",
    "            con_matrix = f1_score_matrix(val_ds, head_model)[1]\n",
    "        else:\n",
    "            f_1 += f1_score_matrix(val_ds, head_model)[0]\n",
    "            con_matrix += f1_score_matrix(val_ds, head_model)[1]\n",
    "\n",
    "    acc = acc/i\n",
    "    f_1 = f_1/i\n",
    "    return acc, f_1, con_matrix\n",
    "        \n",
    "\n",
    "\n",
    "eval_kfolds(data_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "train_images_arr = np.array(list(train_ds.map(lambda x,y: x).as_numpy_iterator()))\n",
    "# flatten images\n",
    "train_images_arr = train_images_arr.reshape(\n",
    "    (\n",
    "        train_images_arr.shape[0], \n",
    "        train_images_arr.shape[1] * train_images_arr.shape[2]\n",
    "    )\n",
    ")\n",
    "\n",
    "pca = PCA(0.99)\n",
    "pca.fit(train_images_arr)\n",
    "PCA(copy = True, iterated_power = 'auto', n_components = 0.99, random_state = None, svd_solver = 'auto', tol = 0.0, whiten = True)\n",
    "n_components = pca.n_components_\n",
    "print(n_components)\n",
    "\n",
    "@tf.py_function(Tout=(tf.float32, tf.int64))\n",
    "def apply_pca(x,y):\n",
    "    x = x.numpy()\n",
    "    x = x.reshape([x.shape[0]*x.shape[1]])\n",
    "    x = x.reshape(1, -1)\n",
    "    return (pca.inverse_transform(pca.transform(x)), y)\n",
    "\n",
    "a = train_ds.map(apply_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Deployment/Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised or Semisupervised Learning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Looprvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
