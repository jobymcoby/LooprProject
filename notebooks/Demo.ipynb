{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\chris\\LooprProject\\Looprvenv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "import scipy\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import tensorflow as tf\n",
    "import PIL.Image as Image\n",
    "import tqdm as notebook_tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"..\\\\archive\"  \n",
    "no_defect_images_folder = os.path.join(dataset_folder, \"NODefect_images\")\n",
    "defect_images_folder = os.path.join(dataset_folder, \"Defect_images\")\n",
    "mask_images_folder = os.path.join(dataset_folder, \"Mask_images\")\n",
    "\n",
    "def gather_filenames(mypath):\n",
    "    filepaths = []\n",
    "    for path, _, files in os.walk(mypath):\n",
    "        for name in files:\n",
    "            filepaths.append(os.path.join(path, name))\n",
    "    return filepaths\n",
    "\n",
    "defect_file_paths = gather_filenames(defect_images_folder)\n",
    "no_defect_file_paths = gather_filenames(no_defect_images_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The textile fabric database consists of 245 images of 7 different fabrics. There are 140 defect-free images, 20 for each type of fabric. With different types of defects, there are 105 images.\n",
    "\n",
    "Images have a size of 4096Ã—256 pixels. Defective images have been denominated as follows: nnnn_ddd_ff.png, where nnnn is the image number, ddd is the defect code, and ff is the fabric code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(defect_file_paths + no_defect_file_paths, columns=['filepath'])\n",
    "df['id'] = df['filepath'].map(lambda x: int(x.split('\\\\')[-1].split('_')[0]))\n",
    "df['defect'] = df['filepath'].map(lambda x: int(x.split('\\\\')[-1].split('_')[1]))\n",
    "df['fabric'] = df['filepath'].map(lambda x: int(x.split('\\\\')[-1].split('_')[2].split('.')[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defect codes\n",
    "DEFECT_CODES = {\n",
    "    0:  'No defect',\n",
    "    2:\t'Broken end',\n",
    "    6:\t'Broken yarn',\n",
    "    10:\t'Broken pick',\n",
    "    16:\t'Weft curling',\n",
    "    19:\t'Fuzzyball',\n",
    "    22:\t'Cut selvage',\n",
    "    23:\t'Crease',\n",
    "    25:\t'Warp ball',\n",
    "    27:\t'Knots',\n",
    "    29:\t'Contamination',\n",
    "    30:\t'Nep',\n",
    "    36:\t'Weft crack'\n",
    "}\n",
    "\n",
    "# Create encoding to be 1-13 instead of 2-36. This is the model output.\n",
    "DEFECT_ENCODINGS = {}\n",
    "\n",
    "for i, key in zip(range(len(DEFECT_CODES)) , DEFECT_CODES.keys()):\n",
    "    DEFECT_ENCODINGS[key] = i\n",
    "\n",
    "df['defect'] = df['defect'].map(lambda x: DEFECT_ENCODINGS[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['filepath'].to_numpy() \n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit([[i] for i in df['defect']]) \n",
    "\n",
    "y = enc.transform([[i] for i in df['defect']]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ds = tf.data.Dataset.from_tensor_slices((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(file_path, label):\n",
    "\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_png(img, channels=1)\n",
    "    \n",
    "    return img, label\n",
    "\n",
    "image_ds = file_ds.map(process_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised or Semisupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Deployment/Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Looprvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
